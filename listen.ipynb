{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as utils\n",
    "import datetime\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "from librosa.util import find_files\n",
    "from librosa.core import load,stft,resample,istft\n",
    "\n",
    "from IPython.display import display, Audio\n",
    "\n",
    "import parameter as C\n",
    "import myutils as ut\n",
    "import network\n",
    "\n",
    "fftpath=C.PATH_FFT\n",
    "model_path = \"./model/model/epoch80.pt\"\n",
    "\n",
    "PATH_FFT = \"./stft_data\"\n",
    "SPEECH_PATH = \"./speech_data\"\n",
    "NOISE_PATH = \"./noise_data\"\n",
    "\n",
    "speechlist = find_files(SPEECH_PATH, ext=\"npy\")\n",
    "noiselist = find_files(NOISE_PATH, ext=\"npy\")\n",
    "\n",
    "random.shuffle(speechlist)\n",
    "random.shuffle(noiselist)\n",
    "\n",
    "if not os.path.exists(PATH_FFT):\n",
    "    os.mkdir(PATH_FFT)\n",
    "noise_num = len(noiselist)\n",
    "\n",
    "i=0    \n",
    "#speech data\n",
    "spec = stft(np.load(speechlist[i]), n_fft=C.FFT_SIZE, hop_length=C.H, win_length=C.FFT_SIZE)\n",
    "fulllen=spec.shape[1]\n",
    "\n",
    "while fulllen<C.PATCH_LENGTH * (C.BATCH_SIZE+1) :\n",
    "    i+=1\n",
    "    conc = stft(np.load(speechlist[i]), n_fft=C.FFT_SIZE, hop_length=C.H, win_length=C.FFT_SIZE)\n",
    "    spec = np.concatenate((spec,conc),1)\n",
    "    fulllen = spec.shape[1]\n",
    "speech_spec = spec[:C.PATCH_LENGTH * (C.BATCH_SIZE+1) ]\n",
    "\n",
    "#noise data\n",
    "spec = stft(np.load(noiselist[random.randint(0, noise_num-1)]), n_fft=C.FFT_SIZE, hop_length=C.H, win_length=C.FFT_SIZE)\n",
    "fulllen=spec.shape[1]\n",
    "\n",
    "while fulllen<C.PATCH_LENGTH * (C.BATCH_SIZE+1) :\n",
    "    i+=1\n",
    "    conc = stft(np.load(noiselist[random.randint(0, noise_num-1)]), n_fft=C.FFT_SIZE, hop_length=C.H, win_length=C.FFT_SIZE)\n",
    "    spec = np.concatenate((spec,conc),1)\n",
    "    space = np.zeros([spec.shape[0],random.randint(1,120)])\n",
    "    spec = np.concatenate((spec,space),1)\n",
    "    fulllen = spec.shape[1]\n",
    "noise_spec = spec[:C.PATCH_LENGTH * (C.BATCH_SIZE+1)]\n",
    "\n",
    "#data mixer\n",
    "speech_spec=speech_spec[:,: C.PATCH_LENGTH * C.BATCH_SIZE]\n",
    "noise_spec=noise_spec[:,: C.PATCH_LENGTH * C.BATCH_SIZE]\n",
    "mix_spec=speech_spec+noise_spec\n",
    "\n",
    "print(\"処理前ミックス\")\n",
    "listen_mix=istft(mix_spec,hop_length=C.H, win_length=C.FFT_SIZE)\n",
    "display(Audio(listen_mix, rate=16000))\n",
    "print(\"処理前話し声\")\n",
    "listen_speech=istft(speech_spec,hop_length=C.H, win_length=C.FFT_SIZE)\n",
    "display(Audio(listen_speech, rate=16000))\n",
    "print(\"処理前打鍵音\")\n",
    "listen_noise=istft(noise_spec,hop_length=C.H, win_length=C.FFT_SIZE)\n",
    "display(Audio(listen_noise, rate=16000))\n",
    "\n",
    "#ここから振幅と位相に分けて処理していきます\n",
    "mix_mag = np.abs(mix_spec)\n",
    "mix_mag /= np.max(mix_mag)\n",
    "mix_phase = np.exp(1.j*np.angle(mix_spec))\n",
    "\n",
    "listen_list=[]\n",
    "for iterate in tqdm(range(C.BATCH_SIZE)):\n",
    "    data = mix_mag[:,C.PATCH_LENGTH * iterate:C.PATCH_LENGTH * (iterate+1)]\n",
    "    data=torch.from_numpy(data.astype(np.float32)).clone()\n",
    "    listen_list.append(data)\n",
    "    \n",
    "tensor_data = torch.stack(listen_list)\n",
    "\n",
    "model = network.UnetConv2()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "mask=model(tensor_data)\n",
    "#%%%%\n",
    "mask[mask < 0.90]=0 #hard mask\n",
    "#%%%\n",
    "h=tensor_data * mask\n",
    "h = h.to('cpu').detach().numpy().copy()\n",
    "\n",
    "q = tensor_data * (1-mask)\n",
    "q = q.to('cpu').detach().numpy().copy()\n",
    "\n",
    "output = h[0,:,:]\n",
    "for i in tqdm(range(1,C.BATCH_SIZE)):\n",
    "    output = np.concatenate([output, h[i,:,:]], 1)\n",
    "print(\"処理後音声\")\n",
    "denoise=istft(output*mix_phase,hop_length=C.H, win_length=C.FFT_SIZE)\n",
    "display(Audio(denoise, rate=16000))\n",
    "\n",
    "output = q[0,:,:]\n",
    "for i in tqdm(range(1,C.BATCH_SIZE)):\n",
    "    output = np.concatenate([output, q[i,:,:]], 1)\n",
    "print(\"処理後音声(打鍵)\")\n",
    "denoise=istft(output*mix_phase,hop_length=C.H, win_length=C.FFT_SIZE)\n",
    "display(Audio(denoise, rate=16000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
